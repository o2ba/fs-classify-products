{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0781dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_ori = pd.read_csv(\"ClassifyProducts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c512510a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61878, 89)\n"
     ]
    }
   ],
   "source": [
    "data_ori.set_index('id', inplace=True)\n",
    "# Pfad zur CSV-Datei anpassen\n",
    "# Load the file afterwards\n",
    "high_corr_pairs = pd.read_csv('high_corr_feature_pairs.csv')\n",
    "\n",
    "features_to_drop = high_corr_pairs['Feature_2'].unique()\n",
    "data_ori.drop(columns=features_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "print(data_ori.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10b1f088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
      "id                                                                           \n",
      "1        1       0       0       0       0       0       0       0       0   \n",
      "2        0       0       0       0       0       0       0       1       0   \n",
      "3        0       0       0       0       0       0       0       1       0   \n",
      "4        1       0       0       1       6       1       5       0       0   \n",
      "5        0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "    feat_10  ...  feat_88  feat_89  feat_90  feat_91  feat_92  feat_93  \\\n",
      "id           ...                                                         \n",
      "1         0  ...        0        0        0        0        0        0   \n",
      "2         0  ...        0        0        0        0        0        0   \n",
      "3         0  ...        0        0        0        0        0        0   \n",
      "4         1  ...        0        0        0        0        0        0   \n",
      "5         0  ...        0        0        1        0        0        0   \n",
      "\n",
      "     target  sum_of_features  variance_of_features  count_nonzero_features  \n",
      "id                                                                          \n",
      "1   Class_1               51              2.476358                      23  \n",
      "2   Class_1               11              0.156609                       9  \n",
      "3   Class_1               14              0.503135                       8  \n",
      "4   Class_1              139             39.947623                      36  \n",
      "5   Class_1               20              0.545455                      11  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "# Alle Feature-Spalten (ohne 'target')\n",
    "feature_cols = data_ori.columns.drop('target')\n",
    "\n",
    "# Summe der Features je Zeile\n",
    "data_ori['sum_of_features'] = data_ori[feature_cols].sum(axis=1)\n",
    "\n",
    "# Varianz der Features je Zeile\n",
    "data_ori['variance_of_features'] = data_ori[feature_cols].var(axis=1)\n",
    "\n",
    "# Anzahl der Nicht-Null-Features je Zeile\n",
    "data_ori['count_nonzero_features'] = (data_ori[feature_cols] != 0).sum(axis=1)\n",
    "\n",
    "print(data_ori.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3465754d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
      "id                                                                           \n",
      "1        1       0       0       0       0       0       0       0       0   \n",
      "2        0       0       0       0       0       0       0       1       0   \n",
      "3        0       0       0       0       0       0       0       1       0   \n",
      "4        1       0       0       1       6       1       5       0       0   \n",
      "5        0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "    feat_10  ...  feat_88  feat_89  feat_90  feat_91  feat_92  feat_93  \\\n",
      "id           ...                                                         \n",
      "1         0  ...        0        0        0        0        0        0   \n",
      "2         0  ...        0        0        0        0        0        0   \n",
      "3         0  ...        0        0        0        0        0        0   \n",
      "4         1  ...        0        0        0        0        0        0   \n",
      "5         0  ...        0        0        1        0        0        0   \n",
      "\n",
      "    target  sum_of_features  variance_of_features  count_nonzero_features  \n",
      "id                                                                         \n",
      "1        1               51              2.476358                      23  \n",
      "2        1               11              0.156609                       9  \n",
      "3        1               14              0.503135                       8  \n",
      "4        1              139             39.947623                      36  \n",
      "5        1               20              0.545455                      11  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "#Transform target column from string to int using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Beispiel: Zielspalte\n",
    "y = data_ori['target']  # oder wie deine Spalte heißt\n",
    "\n",
    "# Initialisieren und anwenden\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Ersetze die alte Zielspalte oder speichere neu\n",
    "data_ori['target'] = y_encoded + 1\n",
    "print(data_ori.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "005e4d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "df=data_ori.copy()\n",
    "\n",
    "X = df.drop(columns='target')\n",
    "y = df['target']\n",
    "\n",
    "# Klassenhäufigkeit\n",
    "class_counts = df['target'].value_counts()\n",
    "\n",
    "# Mittelwert der Klassengrößen berechnen (ganzzahlig)\n",
    "mean_class_size = int(class_counts.mean())\n",
    "\n",
    "# Oversampling-Strategie: Klassen < Mittelwert\n",
    "oversampling_classes = {\n",
    "    label: mean_class_size\n",
    "    for label in class_counts.index\n",
    "    if class_counts[label] < mean_class_size\n",
    "}\n",
    "\n",
    "# Undersampling-Strategie: Klassen > Mittelwert\n",
    "undersampling_strategy = {\n",
    "    label: mean_class_size\n",
    "    for label in class_counts.index\n",
    "    if class_counts[label] > mean_class_size\n",
    "}\n",
    "\n",
    "# Resampler initialisieren\n",
    "smote = SMOTE(sampling_strategy=oversampling_classes, random_state=1)\n",
    "rus = RandomUnderSampler(sampling_strategy=undersampling_strategy, random_state=1)\n",
    "\n",
    "# Pipeline definieren\n",
    "pipeline = Pipeline([\n",
    "    ('SMOTE', smote),\n",
    "    ('RandomUnderSampler', rus)\n",
    "])\n",
    "\n",
    "# Resampling durchführen\n",
    "X_resampled, y_resampled = pipeline.fit_resample(X, y)\n",
    "\n",
    "# Neues DataFrame erzeugen\n",
    "balanced_data = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "balanced_data['target'] = y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52dac678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "1    6875\n",
      "2    6875\n",
      "3    6875\n",
      "4    6875\n",
      "5    6875\n",
      "6    6875\n",
      "7    6875\n",
      "8    6875\n",
      "9    6875\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(balanced_data['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81e8c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feat_1  feat_2  feat_3    feat_4    feat_5    feat_6    feat_7    feat_8  \\\n",
      "0  0.017857     0.0     0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1  0.000000     0.0     0.0  0.000000  0.000000  0.000000  0.000000  0.013158   \n",
      "2  0.000000     0.0     0.0  0.000000  0.000000  0.000000  0.000000  0.013158   \n",
      "3  0.017857     0.0     0.0  0.014286  0.315789  0.166667  0.131579  0.000000   \n",
      "4  0.000000     0.0     0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "   feat_9   feat_10  ...  feat_88  feat_89   feat_90  feat_91  feat_92  \\\n",
      "0     0.0  0.000000  ...      0.0      0.0  0.000000      0.0      0.0   \n",
      "1     0.0  0.000000  ...      0.0      0.0  0.000000      0.0      0.0   \n",
      "2     0.0  0.000000  ...      0.0      0.0  0.000000      0.0      0.0   \n",
      "3     0.0  0.033333  ...      0.0      0.0  0.000000      0.0      0.0   \n",
      "4     0.0  0.000000  ...      0.0      0.0  0.007692      0.0      0.0   \n",
      "\n",
      "   feat_93  sum_of_features  variance_of_features  count_nonzero_features  \\\n",
      "0      0.0         0.093284              0.001746                0.343750   \n",
      "1      0.0         0.018657              0.000103                0.125000   \n",
      "2      0.0         0.024254              0.000348                0.109375   \n",
      "3      0.0         0.257463              0.028294                0.546875   \n",
      "4      0.0         0.035448              0.000378                0.156250   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "cols_to_normalize = balanced_data.drop(columns='target').columns\n",
    "\n",
    "# Skaler initialisieren und anwenden\n",
    "scaler = MinMaxScaler()\n",
    "balanced_data[cols_to_normalize] = scaler.fit_transform(balanced_data[cols_to_normalize])\n",
    "print(balanced_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5767852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data.to_csv('balanced_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
